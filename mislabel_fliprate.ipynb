{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b79f0cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1337\n",
      "Global seed set to 1337\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import shutil\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "import copy\n",
    "import natsort\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "from pytorch_metric_learning import losses\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from networks.unet2d import Unet2D, UNet_OG\n",
    "'''Efficient-Unet'''\n",
    "from networks.EfficientUnet.efficientunet import *\n",
    "from utils.losses import *\n",
    "from utils.util import _eval_dice, _eval_dice_mri, _eval_haus, _connectivity_region_analysis, parse_fn_haus\n",
    "from utils.metrics import dice_coef_metric, iou_metric\n",
    "from utils.aggregators import *\n",
    "#from utils.mislabel import *\n",
    "from dataloaders.prostate_dataloader import Dataset_Prostate, normalize\n",
    "from dataloaders.transforms import train_pro_tfm, eval_pro_tfm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f4ba016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset, model, optimizer for each client\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(1337+worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdf0a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipsis_mask(mask):\n",
    "    #np.random.seed(1)\n",
    "    rands = np.random.randint(1, 5, (2,))\n",
    "    center = np.random.randint(-5, 5, (2,))\n",
    "    \n",
    "    x0 = center[0]; a = rands[0]  # x center, half width                                       \n",
    "    y0 = center[1]; b = rands[1]  # y center, half height\n",
    "    x = np.linspace(-10, 10, mask.shape[-1])  # x values of interest\n",
    "    y = np.linspace(-10, 10, mask.shape[-1])[:,None]  # y values of interest, as a \"column\" array\n",
    "    ellipse = ((x-x0)/a)**2 + ((y-y0)/b)**2 <= 1  # True for points inside the ellipse\n",
    "    ellipse = ellipse.astype('int').reshape(mask.shape)\n",
    "    return ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d5f1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mislabeling(masklist, epc, mis_type=''):\n",
    "    '''set seed'''\n",
    "    random.seed(100+epc)\n",
    "    np.random.seed(100+epc)\n",
    "    \n",
    "    '''convert to numpy'''\n",
    "    masklist = masklist.data.cpu().numpy()\n",
    "    '''split idx for zoom in or out'''\n",
    "    idx = masklist.shape[0] // 2\n",
    "    mismask_full = np.zeros_like(masklist)\n",
    "    \n",
    "    for i, mask in enumerate(masklist):\n",
    "        if mis_type == 'both':\n",
    "            if i <= idx:\n",
    "                '''affine transformation'''\n",
    "                mismask = A.Affine(scale=0.5, rotate=180, p=1)(image=mask)['image']\n",
    "            else:\n",
    "                '''ellipsis mislabeling'''\n",
    "                mismask = ellipsis_mask(mask)\n",
    "        if mis_type == 'affine':\n",
    "            mismask = A.Affine(scale=0.5, rotate=180, p=1)(image=mask)['image']\n",
    "        if mis_type == 'ellip':\n",
    "            mismask = ellipsis_mask(mask)\n",
    "            \n",
    "        mismask_full[i] = mismask\n",
    "    return torch.from_numpy(mismask_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c73ab2",
   "metadata": {},
   "source": [
    "## Prostate Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a568597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 0, w2b_rate=0.356, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 1, w2b_rate=0.335, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 2, w2b_rate=0.33, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 3, w2b_rate=0.327, b2w_rate=0.019, flip_rate=0.024\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 4, w2b_rate=0.328, b2w_rate=0.019, flip_rate=0.024\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 5, w2b_rate=0.332, b2w_rate=0.019, flip_rate=0.024\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 6, w2b_rate=0.333, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 7, w2b_rate=0.333, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 8, w2b_rate=0.334, b2w_rate=0.019, flip_rate=0.025\n",
      "total 421 slices\n",
      "total 782 slices\n",
      "total 233 slices\n",
      "total 984 slices\n",
      "total 468 slices\n",
      "total 257 slices\n",
      "iteration: 9, w2b_rate=0.333, b2w_rate=0.019, flip_rate=0.024\n",
      "0.334 0.019 0.025\n"
     ]
    }
   ],
   "source": [
    "client_num = 6\n",
    "mis_type = 'ellip'\n",
    "source_site_idx = [0, 1, 2, 3, 4, 5]\n",
    "client_name = ['client1', 'client2', 'client3', 'client4', 'client5', 'client6']\n",
    "train_loader_clients = []\n",
    "mislabel_rate = 0.4\n",
    "iterations = 10\n",
    "mis_pool, gd_pool = [], []\n",
    "mse_list = []\n",
    "w2b_list, b2w_list, flip_list = [], [], []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for ite in range(iterations):\n",
    "    for client_idx in range(client_num):\n",
    "            #Prostate\n",
    "            image_list = glob('./dataset/Prostate/{}/data_npy/*'.format(client_name[client_idx]))\n",
    "            #train test split\n",
    "            train, _ = train_test_split(image_list, test_size=0.1, random_state=1337)\n",
    "            train, _ = train_test_split(train, test_size=0.1, random_state=1337)\n",
    "            #we can perform augmentation\n",
    "            train_set = Dataset_Prostate(train, train_pro_tfm)\n",
    "\n",
    "            #dataloader\n",
    "            train_loader = DataLoader(train_set, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "            train_loader_clients.append(train_loader)\n",
    "            dataloader_current = train_loader_clients[client_idx]\n",
    "\n",
    "            for i_batch, sampled_batch in enumerate(dataloader_current):\n",
    "                time2 = time.time()\n",
    "\n",
    "                # obtain training data\n",
    "                #volume_batch: (64, 3, 256,256), label_batch: (64, 1, 256, 256)\n",
    "                volume_batch_raw, label_batch = sampled_batch['image'].to(device), sampled_batch['label'].to(device)\n",
    "\n",
    "                '''if mislabeling'''\n",
    "                if mislabel_rate > 0:\n",
    "                    mis_idx = round(mislabel_rate*label_batch.shape[0]) #compute mislabel idx for normal/mislabel split\n",
    "                    sd = ite + i_batch #seed for mislabeling\n",
    "                    mis_label = mislabeling(label_batch[:mis_idx], sd, mis_type).to(device)\n",
    "                    mis_batch= torch.vstack([mis_label, label_batch[mis_idx:]])\n",
    "                    gd_label = copy.deepcopy(label_batch)\n",
    "                    #append to list\n",
    "                    mis_pool.append(mis_batch.data.cpu().numpy())\n",
    "                    gd_pool.append(gd_label.data.cpu().numpy())\n",
    "            \n",
    "    #stack 6 clients            \n",
    "    mis_masks = np.vstack(mis_pool)\n",
    "    gd_masks = np.vstack(gd_pool)\n",
    "    \n",
    "    tot_pixels = len(gd_masks.flatten())\n",
    "    tot_whites = gd_masks.sum()\n",
    "    tot_blacks = tot_pixels - tot_whites\n",
    "    \n",
    "    #compute difference and count\n",
    "    diff = gd_masks - mis_masks\n",
    "    w2b = (diff > 0).sum()\n",
    "    b2w = (diff < 0).sum()\n",
    "    #compute rate\n",
    "    w2b_rate = w2b/tot_whites\n",
    "    b2w_rate = b2w/tot_blacks\n",
    "    flip_rate = (w2b+b2w) / tot_pixels\n",
    "    \n",
    "    print(f'iteration: {ite}, w2b_rate={round(w2b_rate,3)}, b2w_rate={round(b2w_rate,3)}, flip_rate={round(flip_rate,3)}')\n",
    "    w2b_list.append(w2b_rate)\n",
    "    b2w_list.append(b2w_rate)\n",
    "    flip_list.append(flip_rate)\n",
    "    #eval_mse = round(mse_loss(mis_masks, gd_masks),3)\n",
    "    #print(f'iteration: {ite}, mse={eval_mse}')\n",
    "    #mse_list.append(eval_mse)\n",
    "\n",
    "\n",
    "mean_w2b_rate, mean_b2w_rate, mean_flip_rate = round(np.mean(w2b_list),3), round(np.mean(b2w_list),3), round(np.mean(flip_list),3) \n",
    "print(mean_w2b_rate, mean_b2w_rate, mean_flip_rate)\n",
    "#mean_mse = round(np.mean(mse_list),3)\n",
    "#mean_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108756b",
   "metadata": {},
   "source": [
    "# LGG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c837c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 0, w2b_rate=0.654, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 1, w2b_rate=0.661, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 2, w2b_rate=0.661, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 3, w2b_rate=0.66, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 4, w2b_rate=0.662, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 5, w2b_rate=0.661, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 6, w2b_rate=0.662, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 7, w2b_rate=0.66, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 8, w2b_rate=0.66, b2w_rate=0.02, flip_rate=0.027\n",
      "total 1521 slices\n",
      "total 833 slices\n",
      "total 518 slices\n",
      "total 289 slices\n",
      "iteration: 9, w2b_rate=0.659, b2w_rate=0.02, flip_rate=0.027\n",
      "0.66 0.02 0.027\n"
     ]
    }
   ],
   "source": [
    "client_num = 4\n",
    "mis_type = 'both'\n",
    "source_site_idx = [0, 1, 2, 3]\n",
    "client_name = ['client1', 'client2', 'client3', 'client4']\n",
    "train_loader_clients = []\n",
    "mislabel_rate = 0.8\n",
    "iterations = 10\n",
    "mis_pool, gd_pool = [], []\n",
    "mse_list = []\n",
    "w2b_list, b2w_list, flip_list = [], [], []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for ite in range(iterations):\n",
    "    for client_idx in range(client_num):\n",
    "            #Prostate\n",
    "            image_list = glob('./dataset/LGG/{}/data_npy/*'.format(client_name[client_idx]))\n",
    "            #train test split\n",
    "            train, _ = train_test_split(image_list, test_size=0.1, random_state=1337)\n",
    "            train, _ = train_test_split(train, test_size=0.1, random_state=1337)\n",
    "            #we can perform augmentation\n",
    "            train_set = Dataset_Prostate(train, train_pro_tfm)\n",
    "\n",
    "            #dataloader\n",
    "            train_loader = DataLoader(train_set, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "            train_loader_clients.append(train_loader)\n",
    "            dataloader_current = train_loader_clients[client_idx]\n",
    "\n",
    "            for i_batch, sampled_batch in enumerate(dataloader_current):\n",
    "                time2 = time.time()\n",
    "\n",
    "                # obtain training data\n",
    "                #volume_batch: (64, 3, 256,256), label_batch: (64, 1, 256, 256)\n",
    "                volume_batch_raw, label_batch = sampled_batch['image'].to(device), sampled_batch['label'].to(device)\n",
    "\n",
    "                '''if mislabeling'''\n",
    "                if mislabel_rate > 0:\n",
    "                    mis_idx = round(mislabel_rate*label_batch.shape[0]) #compute mislabel idx for normal/mislabel split\n",
    "                    sd = ite + i_batch #seed for mislabeling\n",
    "                    mis_label = mislabeling(label_batch[:mis_idx], sd, mis_type).to(device)\n",
    "                    mis_batch= torch.vstack([mis_label, label_batch[mis_idx:]])\n",
    "                    gd_label = copy.deepcopy(label_batch)\n",
    "                    #append to list\n",
    "                    mis_pool.append(mis_batch.data.cpu().numpy())\n",
    "                    gd_pool.append(gd_label.data.cpu().numpy())\n",
    "            \n",
    "    #stack 6 clients            \n",
    "    mis_masks = np.vstack(mis_pool)\n",
    "    gd_masks = np.vstack(gd_pool)\n",
    "    \n",
    "    tot_pixels = len(gd_masks.flatten())\n",
    "    tot_whites = gd_masks.sum()\n",
    "    tot_blacks = tot_pixels - tot_whites\n",
    "    \n",
    "    #compute difference and count\n",
    "    diff = gd_masks - mis_masks\n",
    "    w2b = (diff > 0).sum()\n",
    "    b2w = (diff < 0).sum()\n",
    "    #compute rate\n",
    "    w2b_rate = w2b/tot_whites\n",
    "    b2w_rate = b2w/tot_blacks\n",
    "    flip_rate = (w2b+b2w) / tot_pixels\n",
    "    \n",
    "    print(f'iteration: {ite}, w2b_rate={round(w2b_rate,3)}, b2w_rate={round(b2w_rate,3)}, flip_rate={round(flip_rate,3)}')\n",
    "    w2b_list.append(w2b_rate)\n",
    "    b2w_list.append(b2w_rate)\n",
    "    flip_list.append(flip_rate)\n",
    "    #eval_mse = round(mse_loss(mis_masks, gd_masks),3)\n",
    "    #print(f'iteration: {ite}, mse={eval_mse}')\n",
    "    #mse_list.append(eval_mse)\n",
    "\n",
    "\n",
    "mean_w2b_rate, mean_b2w_rate, mean_flip_rate = round(np.mean(w2b_list),3), round(np.mean(b2w_list),3), round(np.mean(flip_list),3) \n",
    "print(mean_w2b_rate, mean_b2w_rate, mean_flip_rate)\n",
    "#mean_mse = round(np.mean(mse_list),3)\n",
    "#mean_mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedpro",
   "language": "python",
   "name": "fedpro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
